{"name":"A Huffman Codes Primer","tagline":"How to Create Your Own Huffman Encoding From Any Source Text","body":"### Why Do I Care About Encoding Text?\r\n\r\nIf you have ever heard of ASCII before, then you've heard of at least one text encoding method, a fairly simple one with 7 bits for each character. Java uses another one, that's 16-bits, but can be used to express a wider range of character types. These and other types of text encodings are used to transmit text as data over any kind of connection.  They are usually a fixed number of bits, with different unique configurations representing a different unique character.  \r\n\r\nNow if you're just transmitting a few words here and there, it's probably irrelevant what kind of encoding you're using. But what about if we'd like to transmit large amounts of text as efficiently as possible. That's where the number of bits you're using comes into play. If I have a very simple language that only contains 10 letters, I can represent those letters easily with just 4 bits. However, if I'm using ascii encoding to send them, I will end up with a lot of wasteful overhead. Similarly, even if I have a more complex language, it's likely that some of my characters will show up far more often than others, e.g. an 'e' in English text. If this is the case, it seems inefficient to be sending all my 'e's with just as many bits as my far less frequent letters. This is where the idea of Huffman codes come from.\r\n\r\n### What Does Huffman Code Mean?\r\n\r\nExtending this idea just a bit farther, it seems likely that we could come up with a variable encoding method, rather than fixed, for whatever language type we are planning to transmit. This would save us a lot of space if, for instance, we could figure out which characters are common, and represent those with very short bit combinations. In kind, we would need to have longer combinations for the less common characters, otherwise we would run out of possible combinations for all the characters in our language. But this is a good tradeoff for efficiency! (assuming we can accurately discover which are the most frequently used characters). And this is exactly what a Huffman Code refers to- it's a way of encoding a certain set of characters based on the frequencies by which they occur in the set, with the goal of minimizing bit length while keeping a unique combination available for every character. This may sound complicated at first. But with relatively simple data structures, it becomes achievable, and we're going to walk through it here step by step.\r\n\r\n### Constructing A Proper Encoding Scheme\r\n\r\nWith ASCII, or other common fixed bit encodings, we know exactly where a certain character starts and stops in an encoding, because they are all the same number of bits. So, if I see: _1101100110110011011110100000_, I can parse out each letter easily by just counting by 7 bits. With a Huffman code on the other hand, this isn't so easy, since the point is that the bit encodings are all different lengths. It must be a requirement then that no encoded character can be a prefix for the encoding of another character. That way, once we see an encoding we recognize, we know to stop and convert it right there, rather than wondering if it's just the start of a longer character's encoding. With this uniqueness in mind, what's the best way to construct this encoding scheme?\r\n\r\nIt turns out that a very good way to do this, is using trees and a priority queue. Imagine this - you have a binary tree where each leaf has the value of a letter in your language, and the parent of those leaves is a super node with a value consisting of each of the values of its children concatenated together, and so on and so forth up the tree. Eventually, at the top of the tree is a node containing all characters in the language. This is the starting point for encoding a character into its binary counterpart.  \r\n\r\n### Encoding and Decoding with a Huffman Tree\r\nIf you've been following so far, we have a binary tree with one big node at the top, with a value containing all the characters in the language. As we branch down, the children each contain some number of those characters, together making up the total set of the language. Then each of those children branch down further into their own children, of which each one takes a certain set of the parent's characters. It continues on this way until it terminates at the leaves, one for each character, each in a unique spot in the tree. It's a unique spot because no other leaf has that exact path to it from the root node. This is important! This gives us our unique encoding with no overlapping prefixes. If we simply start at the top and trace a path down to the leaf node containing the character we're looking for, and write a 1 for every right branch taken, and a 0 for every left branch taken, we will compose a binary number representing that character in the encoding. Not too bad. \r\n\r\nThis is a piece of Javascript code to do just that if you're interested in implementing it: \r\n\r\n````var encodeString = function(input, huffmanTree) {\r\n      var inputArr = input.split(\"\");\r\n      var output = [];\r\n\r\n      var traverse = function (huffmanTree, input) {\r\n        if (huffmanTree.val === input) {\r\n          return;\r\n\t  } else if (huffmanTree.right && huffmanTree.right.val.indexOf(input) >= 0) {\r\n\t    output.push('1');\r\n\t    traverse(huffmanTree.right, input);\r\n\t  } else if (huffmanTree.left && huffmanTree.left.val.indexOf(input) >= 0) {\r\n\t    output.push('0');\r\n\t    traverse(huffmanTree.left, input);\r\n\t    }\r\n\t  };\r\n\r\n      for (var i = 0; i < inputArr.length; i++) {\r\n        traverse(huffmanTree, inputArr[i]); \r\n      }\r\n      return output.join('');\r\n    };\r\n\r\nWhat about decoding? If we wish to decode a binary string to its original character, we do the exact same process in reverse. We start at the top and traverse left and right, following the order of the binary string, and depending on whether we read a 1 or a 0 next. Finally we will arrive at a unique branch containing our character, which we write, and continue on from the top with the rest of the binary. The implementation for that is very similar to the above, so I won't show all of it here, though you can access it in the repo attached to this page.  \r\n\r\n### Constructing the Tree\r\n\r\nSo now we've seen how to encode and decode characters using a Huffman tree. But where does the tree come from in the first place? Well, that's the crux of this encoding algorithm, and it's also the tricky part. Seemingly we can construct it any way we wish, as long as we have a unique leaf for every character and the tree relatively balanced, it will work for our purposes, right? Well, technically yes, but remember that the whole point of this encoding is to save time and space by giving frequently used characters much shorter encoded strings than those infrequently used.  If we don't do that, we might as well just use fixed bit encoding. We can accomplish that goal by building the tree in a special way, using a priority queue to keep track of which characters are frequently or infrequently used in whatever language we base the tree on.\r\n\r\nThe way a priority queue works is that it takes in elements- just like a regular queue, but each element has a priority value attached to it. This tells the queue how important it is compared to the other elements, and in fact it determines the order in which elements are extracted. This means that a priority queue is not FIFO, but rather more like a self-sorting array. Except that the 'sorting' happens when you go to extract something. The queue will do some calculation to find the highest priority item and return that first. In our implementation, we want to start building the tree from the bottom up, starting with the least frequent characters, so we will choose to sort our queue in ascending order of frequency of occurrence.\r\n\r\nThe process of constructing the Huffman Tree is to first create a single node tree for every character seen in the base language, and push them into the queue with their frequencies as their priorities. Now we pull the two least frequent trees and create a super tree with value containing both of those characters, and new priority equal to the sum of the two lesser priorities. This tree we push back into the queue.  We pull the next two lowest priority nodes, and do the same thing, combining them into a new tree node, placing them as its children and pushing that back into the queue with its new priority. We continue in this way until there is only one element left in the queue, and its the entire Huffman Tree. This has the intended effect of having the nodes higher up in the tree be much more frequently occurring characters, thus giving them shorter encodings.  Now we can use the tree to encode and decode whatever we want. \r\n\r\nHere is some Javascript code to do that construction process:\r\n\r\n````var makeHuffmanTree = function(corpus) {\r\n\r\n      var countFrequency = function(textBody) {\r\n        var freqObj = {};\r\n        //split to remove spaces, then get individual letters, and count occurrence in an object\r\n        var letters = textBody.split('');\r\n        letters.forEach(function(letter) {\r\n          //double tilde coerces to 0 if undefined, otherwise just the number, then add 1;\r\n          freqObj[letter] = ~~freqObj[letter] + 1;\r\n        });\r\n        return freqObj;\r\n      };\r\n\r\n      var queue = new PriorityQueue();\r\n      var frequenciesObj = countFrequency(corpus);\r\n      //Construct a tree for each letter, and insert them into the\r\n      //pqueue according to their frequency\r\n      for (var key in frequenciesObj) {\r\n        var freq = frequenciesObj[key];\r\n        var tree = new Tree([key]);\r\n        queue.insert(freq, tree);\r\n      }\r\n      \r\n      while (queue.size() > 1) {\r\n        var element1 = queue.extract();\r\n        var element2 = queue.extract();\r\n\r\n        var superTree = new Tree(element1.val.val.concat(element2.val.val));\r\n        superTree.left = element1.val;\r\n        superTree.right = element2.val;\r\n        queue.insert(element1.key + element2.key, superTree);\r\n      }\r\n\r\n      return queue.extract().val;\r\n    };\r\n\r\nThis code makes the assumption that you have a functioning priority queue doing proper element extraction. But if that's the case, this will construct the tree based on whatever _corpus_ you pass in, meaning a body of text to base the algorithm on. This is where the algorithm will get its character frequencies from. If you pass in something in French, for example, the encoding will work very well for French sentences, but the same letters may not be as frequent in English, so the encoding scheme probably won't be as efficient. So you want to make sure to tailor your input to the type of thing you're planning to encode. At the very least, make sure every letter you're planning to encode appears at least once in the body of the corpus you pass in. \r\n\r\nThat's the whole process of creating a Huffman Tree and using it to encode and decode text. If you'd like to mess around with this stuff more, the repo attached to this page has a Demo.html file that will do Huffman encodings based on any corpus you put in, and will even tell you how efficient it is at encoding things. \r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}